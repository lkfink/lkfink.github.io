---
layout: page
title: Publications
description: Lauren Fink's publications
---
<HEAD>
<!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-114823830-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-114823830-1');
  </script>
</HEAD>

<div class="navbar">
    <div class="navbar-inner">
        <ul class="nav">
            <li><a href="#articles">Articles</a></li>
            <li><a href="#abstracts">Abstracts</a></li>
            <li><a href="#editor">Edited volumes</a></li>
            <li><a href="#thesis">Thesis</a></li>
            <li><a href="#dissertation">Dissertation</a></li>
        </ul>
    </div>
</div>





### <a name="articles"></a>Articles

#### 2018

**Fink, L.**, Hurley, B., Geng, J. & Janata, P. (submitted). A linear oscillator model predicts dynamic temporal attention and pupillary sensorimotor synchronization to rhythmic musical patterns.  

**Fink, L.** & Lange, E. (in press). The application of eye-tracking in music research. *Journal of Eye Movement Research.*  

Hurley, B., **Fink, L.**, & Janata, P. (in press). Mapping the dynamic allocation of attention in musical patterns. *Journal of Experimental Psychology: Human Perception & Performance.* DOI: 10.1037/xhp0000563

#### 2017
**Fink, L.** (2017). Chance Operations in Neuroscience.  In J. Lane & L. Fink (Eds.), *Allen Otte Folio* (pp. 17-20).  

#### 2016
**Fink, L.** (2016). *The Greatest.* [Pulse Special Issue of Ethnomusicology Review/Sounding Board.](http://ethnomusicologyreview.ucla.edu/sounding-board/special-issue){:target="_blank"} 


<br>
<br>



### <a name="abstracts"></a>Conference abstracts  

#### 2018

**Fink, L.**, Lange, E., Janata, P. (2018, July). The pupil entrains to prominent periodicities in music. *Talk to be presented at the International Conference on Music Perception & Cognition, Graz, Austria.* 

**Fink, L.**, Hurley, B., Geng, J., & Janata, P. (2018, May). Predicting attention and motor responses to musical patterns. *Poster presented at the Stanford Music & Brain Symposium, Palo Alto, CA.*

**Fink, L.**, Ribeiro, J., & White, V. (2018, March). Transforming graduate writing experiences: A new Writing Across the Curriculum (WAC) certificate program. *Symposium presented at the College Composition and Communication Convention, Kansas City, MO.*

#### 2017
Lange, E. & **Fink, L.** (2017, August). Symposium: Using eye-tracking and pupillometry to study rhythmic processing in music and dance. *Proceedings of the European Conference on Eye Movements, Wüppertal, Germany,* pgs. 73-75.

**Fink, L.**, Geng, J., Hurley, B. & Janata, P. (2017, August). Predicting attention to auditory rhythms using a linear oscillator model and pupillometry. *Conference on Music & Eye-Tracking, Frankfurt, Germany.*

Hurley, B., **Fink, L.**, & Janata, P. (2017, March). A resonator model predicts temporal orienting in rhythmic music. *Proceedings of the Cognitive Neuroscience Society Annual Meeting.* 

Bright, A., Singleton, J., **Fink, L.**, & Rodger, K. (2017, March). Cultivating a Rhetorical Consciousness: Supporting Graduate Student Writers Across the Curriculum. *Symposium presented at the College Composition and Communication Convention, Portland, OR.*

#### 2016
**Fink, L.**, Hurley, B., Geng, J. & Janata, P. (2016, July). Pupillary and eyeblink responses to auditory stimuli index attention and sensorimotor coupling. *Proceedings of the 14th International Conference for Music Perception & Cognition*, pg. 788. 

Hurley, B., **Fink, L.**, & Janata, P. (2016, July). Predicting temporal attention in music with a damped oscillator model. *Proceedings of the 14th International Conference for Music Perception & Cognition*, pg. 782

**Fink, L.** & Rodger, K. (2016, June). Mapping Neuroscience through Professional Writing. *Talk presented at the International Writing Across the Curriculum Conference, Ann Arbor, MI.*

#### 2015
**Fink, L.** (2015, July). Eyeblinks as biomarkers of temporal coordination during music cognition. *Poster presented at the Rhythm Perception & Production Workshop, Amsterdam, Netherlands.*

#### 2014
**Fink, L.**, Niemeyer, T., Jones, S., Larabee, Z., & Schuette, P. (2014, November). Oscillator Etudes. *Performance premiere at the Percussive Arts Society International Convention, Indianapolis, IN.* 

#### 2013
**Fink, L.** & Mazman, A. (2013, July). False belief attribution: An investigation of the neural pattern account. *Poster presented at the Society for Philosophy and Psychology Conference, Providence, RI.*


<br>
<br>


### <a name="editor"></a>Edited volumes

**Fink, L.** & Lange, E. (2018, rolling/forthcoming). [Special Issue on Music & Eye-Tracking](https://bop.unibe.ch/JEMR/issue/view/793){:target="_blank"}. *Journal of Eye Movement Research*.  

**L. Fink** (Ed.) (2017). [*Explorations: The UC Davis Undergraduate Research Journal*. (Vol. 19).](http://explorations.ucdavis.edu/2017/index.html){:target="_blank"} The Regents of the University of California.    

J. Lane & **L. Fink** (Eds.). (2017). *Allen Otte Folio.* [Preview ![Program as pdf](icons16/pdf-icon.png)]({{ BASE_PATH }}/assets/Otte_Folio_preview.pdf){:target="_blank"}  



<br>
<br>



### <a name="thesis"></a>Masters thesis
#### Music modulates eyeblinks: An examination of temporal coordination.

Supervised by [Ian Cross](http://www.mus.cam.ac.uk/directory/ian-cross){:target="_blank"} 

##### Abstract: 
Eyeblinks have yet to attract significant attention in music cognition research, though they have been studied extensively in other domains. Rather than an artifact to be removed in eye tracking or EEG data, eyeblinks, and their connection with musical behaviors, warrant proper exploration.

**Background:** Eyeblinks tend to occur at structurally salient breaks during both reading and speech; they are likely to occur at the ends of sentences and paragraphs in a text, or at pauses and turns in speech (Orchard & Stern, 1991; Cummins, 2012). Interestingly, blinks are often synchronized, or temporally coordinated, between speakers (Nakano & Kitazawa, 2010); however, individuals with autism spectrum disorders fail to show such synchrony, perhaps indicating that temporal coordination is at the root of social communication impairments (Nakano et al., 2011).

Further, eyeblinks can be read as indicators of a variety of psychological and clinical states (Oh et al., 2012). Mirroring attention/arousal and modulated by dopamine (DA), eyeblinks reveal information about sleepiness, attentiveness, and the difficulty of a task (Ponder & Kennedy, 1927; Schleicher et al., 2008). Blink rate (BR) is directly proportional to DA levels, with Parkinson’s patients (low DA/low BR) and schizophrenics (high DA/high BR) at opposite ends of the dopamine/blinking spectrum (Barbato et al., 2012; Colzato et al., 2009; Esteban et al., 2004). Such dopamine-linked disorders typically involve disruptions in timing and/or motor processes, mediated by brainstem structures like the basal ganglia and cerebellum.
Eyeblink analysis is an established neuropsychological tool – used to evaluate dopamine function, cognitive load, and both temporal and social coordination. Such analysis can reasonably be expected to be relevant in the scientific study of music.

**Present Aims:** Because eyeblinks have clear social and clinical implications, the goal of this thesis is to examine the role eyeblinks might play in music cognition and to discuss the results of a sight- reading experiment conducted at the Conservatorium van Amsterdam. Results of the experiment suggest that, in general, eyeblinks are suppressed while sight-reading; however, blinks that do occur tend to be at musical phrase transitions or at other structurally relevant musical instances. While there is variability across participants in average number of blinks per reading, there is an incredible amount of consistency on an individual basis in average number of blinks, as well as musical/temporal location of blinks across readings. Overall, it seems that eyeblinks provide insights into an individual’s chunking of musical information and are likely to be a particularly useful evaluative tool in pedagogical and/or therapeutic settings, in addition to experimental ones.

[Full Text Available for download on ResearchGate](https://www.researchgate.net/publication/267752012_Music_modulates_eyeblinks_An_examination_of_temporal_coordination){:target="_blank"}


<br>
<br>



### <a name="dissertation"></a>Doctoral dissertation
[Dissertation still in progress. Check back in about a year for the full document]  

#### PROJECT SUMMARY 
Music is present in all known human cultures and is commonly used to facilitate social interactions, mood/arousal regulation, and therapeutic change. As such, music is a potent, ethologically valid tool for studying the neural mechanisms of attention and interpersonal coordination. In this project, we use a combination of computational modeling, psychophysics, eye-tracking, and electroencephalography (EEG) to measure and predict dynamic attention to auditory stimuli. Specifically, we aim to 1) assess the potential of a stimulus-driven linear oscillator model to predict attention to complex musical stimuli and 2) determine the relationship between ocular and cortical responses to auditory rhythms and whether pupil dynamics can index auditory attention in a manner similar to EEG signatures.  

Evidenced through perceptual thresholds for detecting change at various points in time, as well as pupillary and eyeblink responses, preliminary results reveal that temporal structure in musical patterns enhances attention to specific points in time over others. Further, we have found that ocular motor changes are systematically related to auditory ones. Such correspondence between ocular data and auditory stimuli provides a potential mechanistic explanation for the enhanced visual target detection that has been shown to occur in the presence of rhythmic auditory stimuli, as well as the changes in visual experience often reported during music listening. We have shown that our linear oscillator model can predict not only participants’ perceptual thresholds but also the continuous pupillary response to musical patterns. To our knowledge, we are the first to show that the pupil can become entrained by rhythmic auditory stimuli.  

In sum, our model is a promising tool for predicting continuous attentional (behavioral and physiological) responses to novel auditory stimuli. The additional analysis to be completed as part of my dissertation research will assess our model’s usefulness in predicting cortical electrophysiology in relation to auditory stimuli, as well as the relationship between ocular and cortical electrophysiological data. Ultimately, this research will enhance our understanding of how the brain responds to complex musical patterns and provide insights for harnessing the effects of music to enhance or alter attentional states.  

#### INNOVATION & SIGNIFICANCE
At present, leading models of temporal attention can only predict prominent periodicities present in an audio signal. This research will assess a time-varying prediction of temporal salience. In other words, rather than a broad average of the expected behavior resulting from an audio signal, we aim to predict on an instant-by-instant basis the attentional fluctuations elicited by auditory stimuli. To investigate our linear oscillator model’s predictions, we have developed a couple of novel approaches. The first is an adaptive thresholding paradigm to measure perceptual thresholds for detecting change at various points in time throughout an on-going auditory scene. The second is the use of eye-tracking in such an auditory context. Though eye-tracking is a common methodology in other subfields of neuroscience, using motor behaviors such as eyeblinks and pupil dilation to index temporal attention to auditory scenes is relatively novel. Blinks and pupil dilation index striatal dopamine and the locus coeruleus norepinephrine system, respectively. These two neurotransmitter systems can otherwise only be studied in humans using invasive techniques such as PET imaging. Eye-tracking therefore provides an inexpensive, non-invasive way to understand the role of these two neurotransmitter systems in the context of auditory processing.  

To evaluate the similarity of the temporal characteristics of the pupillary signal to cortical EEG, we will be developing novel analytical techniques. At present, very few studies treat the pupil signal as continuous; instead averages are taken following specific events of interest. Here we will do time-frequency analyses on the pupillary signal as well as the EEG, comparing their prominent frequency spectra and assessing any potential nested oscillatory activity. Similarly, the timing of blinks in relation to pupillary and cortical oscillations may also provide novel insights as to how the nervous system processes complex, rhythmically structured sound.
The proposed research will provide a basic understanding of the ways in which the oculomotor system is influenced by temporally regular auditory stimuli. In addition to evaluating novel dependent measures in the context of auditory processing, this work will lay the foundation for future studies investigating the use of auditory stimuli to guide or distract from visual attention. The development and fine-tuning of our computational model in relation to this research will be a significant step forward for the computational music and auditory neuroscience research communities. All code for our model is publicly available for download as part of the [Janata Lab Music Toolbox](http://atonal.ucdavis.edu/resources/software/jlmt/){:target="_blank"}.

