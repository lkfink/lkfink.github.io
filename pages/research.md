---
layout: page
title: Research
description: Lauren Fink's research projects
---
<HEAD>
<!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-114823830-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-114823830-1');
  </script>
</HEAD>

<div class="navbar">
    <div class="navbar-inner">
        <ul class="nav">
            <li><a href="#Modeling attention">Modeling attention</a></li>
            <li><a href="#GEM">GEM</a></li> 
            <li><a href="#Mobile eye-tracking">Mobile eye-tracking</a></li>
            <li><a href="#MET">MET</a></li> 
            <li><a href="#WAC">WAC</a></li> 
        </ul>
    </div>
</div>



### <a name="Modeling attention"></a>Modeling attention to music
In this project, Lauren uses a combination of computational modeling, psychophysics, eye-tracking, and electroencephalography (EEG) to measure and predict dynamic attention to auditory stimuli. Specifically, she aims to 1) assess the potential of a stimulus-driven [linear oscillator model](http://atonal.ucdavis.edu/projects/musical_spaces/rhythm/btb/){:target="_blank"} to predict attention to complex musical stimuli and 2) determine the relationship between ocular and cortical responses to auditory rhythms and whether pupil dynamics can index auditory attention in a manner similar to EEG signatures.

<iframe width="560" height="315" src="https://www.youtube.com/embed/OMVWDExIq38" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

This video shows oscillations in pupil size while listening to a clip of music. The video is sped up 5x.

##### Papers related to this project:  

> **Fink, L.**, Hurley, B., Geng, J. & Janata, P. (2018). A linear oscillator model predicts dynamic temporal attention and pupillary sensorimotor synchronization to rhythmic musical patterns.  *Journal of Eye Movement Research, 11*(2):12. [DOI: 10.16910/jemr.11.2.12](https://bop.unibe.ch/JEMR/article/view/4285/){:target="_blank"}.  

> Hurley, B., **Fink, L.**, & Janata, P. (2018). Mapping the dynamic allocation of attention in musical patterns. *Journal of Experimental Psychology: Human Perception & Performance.* Advance online publication. [DOI: 10.1037/xhp0000563](http://psycnet.apa.org/doiLanding?doi=10.1037%2Fxhp0000563){:target="_blank"}  


<br><br>

### <a name="GEM"></a>Groove Enhancement Machine (GEM)
This project involves a real-time adaptive music making device to enhance synchrony between groups of people tapping together. Lauren is in the process of writing up the results of this project. All code and hardware specifications will eventually be publicly available. Check back in a few months for more details. 

This short documentary, directed by Joerg Altekruse, highlights an early prototype of the project, as well as related work in the Janata Lab.

<iframe title="Groove-Maschine" allowfullscreen="true" style="transition-duration:0;transition-property:no;margin:0 auto;position:relative;display:block;background-color:#000000;" frameborder="0" scrolling="no" width="720" height="406" src="https://www.arte.tv/player/v3/index.php?json_url=https%3A%2F%2Fapi.arte.tv%2Fapi%2Fplayer%2Fv1%2Fconfig%2Fde%2F074208-005-A%3Fautostart%3D0%26lifeCycle%3D1&amp;lang=de_DE&amp;mute=0"></iframe>

##### Conference presentations related to this project (paper in prep.):

> **Fink, L.**, Alexander, P., Janata, J. (2019, March). Bringing groups of people into greater temporal and psychological synchrony using a multi-person adaptive metronome. *Poster presented at the Cognitive Neuroscience Society Meeting, San Francisco, CA.*  

> **Fink, L.**, & Alexander, P., & Janata, P. (2017, July). Fostering Empathy and Improving Focus Through the Groove Enhancement Machine: Facilitating Sensorimotor Coordination and Cooperation Among Groups of Individuals. *Demonstration presented at the National Academies Keck Futures Initiative Art, Science, Engineering, and Medicine Mid-Cycle Grant Meeting, Boston, MA.*

<!-- ![groove enhancement machine collage]({{ BASE_PATH }}/assets/publpics/gem_example.png)  -->

<br><br>

### <a name="Mobile eye-tracking"></a>Mobile eye-tracking

Lauren is currently using [Pupil Labs'](https://pupil-labs.com/){:target="_blank"} mobile eye-tracking headsets in a variety of music/neuroscience projects. For anyone considering purchasing from Pupil Labs, Lauren previously wrote up a [short guide of considerations](http://lkfink.github.io/pages/PupilLabs_aBeginnersGuide.html){:target="_blank"}. 
 
![pupil labs collage]({{ BASE_PATH }}/assets/publpics/puplabs_collage.png) 

At the [Max Planck Institute for Empirical Aesthetics](https://www.aesthetics.mpg.de/en.html){:target="_blank"}, Lauren, together with [Elke Lange](https://www.aesthetics.mpg.de/en/the-institute/people/lange.html){:target="_blank"}, would like to bring mobile eye-tracking into the concert hall ([ArtLab](https://www.aesthetics.mpg.de/index.php?id=625&L=1){:target="_blank"}). Project description below: 

The increasing availability of cost-effective, mobile, physiological measurement devices is leading to a growing interest in live, concert research studies in an attempt to understand how changes in audience members’ or musicians’ physiology relate to their subjective experiences. Such studies are still in their infancy, as they require a great deal of technical expertise in terms of hardware and software, as well as resources (e.g. a concert hall equipped for data collection, funding for scientific staff, physiological recording devices, etc.). To date, researchers have used methods like motion capture and mobile EEG to examine things like head bobbing or brain wave synchronization between audience members during a live vs. recorded music concert. Here, we propose the use of mobile eye-trackers in the concert hall. 

While it may seem odd to use eye-tracking (vision) in a musical (auditory) context, a growing number of laboratory studies have clearly established that sound systematically affects visual processing. However, eye-tracking has yet to be widely adopted in auditory, and more specifically, musical, contexts. Previously, mobile eye-trackers have been used to examine gaze patterns of up to 3 musicians playing together; however, no studies have examined mobile eye-tracking data from multiple audience members at a concert, in addition to the musicians on stage. Such an undertaking would allow for comparisons of:
-	gaze location (what audience members and what musicians are looking at)
-	eye movement dynamics (when, in relation to musical events, and each other, audience members and musicians shift their gaze)
-	blink rate (how often people blink) and blink timing (when people blink)
These measures will allow us to answer a number of questions about how and when music affects ocular dynamics, e.g. which elements of a concert lead to synchronized ocular activity across audience members and/or musicians on stage. On a lower level, we can also answer questions about which neural mechanisms may underlie certain aspects of musical processing, as many ocular measures have well established neural substrates. Further, we can pit auditory and visual saliency against each other to answer questions related to cross-modal interactions.  


<br><br>

### <a name="MET"></a>Conference on Music and Eye-Tracking (MET)

In August 2017, Lauren Fink and [Elke Lange](https://www.aesthetics.mpg.de/en/the-institute/people/lange.html){:target="_blank"} organized the [Conference on Music & Eye-Tracking](https://www.ae.mpg.de/met17){:target="_blank"}, which was held at the Max Planck Institute for Empirical Aesthetics in Frankfurt, Germany. <br/>  

Conference Program: [![Click here to view the MET conference program](icons16/pdf-icon.png)]({{ BASE_PATH }}/assets/MET17-Konferenzbroschüre.pdf){:target="_blank"}   <br/>  

A [Special Issue on Music and Eye-Tracking](https://bop.unibe.ch/JEMR/issue/view/793){:target="_blank"} with selected presentations from the conference was published in the Journal of Eye Movement Research.  

> **Fink, L.**, Lange, E. & Groner, R. (2019). The application of eye-tracking in music research. *Journal of
Eye Movement Research, 11(2)*:1. DOI: 10.16910/jemr.11.2.1.

[![METimage](../../assets/publpics/METimage.png)](https://lkfink.github.io/pages/publpics/METimage.html){:target="_blank"} 

#### Upcoming 2020 Conference! (CANCELLED)
The second Conference on Music & Eye-Tracking will be held at the Max Planck Institute for Empirical Aesthetics, 16-17 July 2020. More information will be posted as it becomes available: [www.ae.mpg.de/met](https://www.ae.mpg.de/met){:target="_blank"}.



<br><br>

### <a name="WAC"></a>Writing Across the Curriculum (WAC)
Lauren served for three years as the lead Graduate Writing Fellow in the University of California Davis's Writing Across the Curriculum program. In this role, she managed a team of six Graduate Writing Fellows and acted as a liason between graduate fellows and faculty. The WAC fellows hold one-on-one [writing consultations](http://writing.ucdavis.edu/wac/consultations){:target="_blank"} with graduate students and postdocs from any discipline, offer writing [retreats](http://writing.ucdavis.edu/wac/retreats){:target="_blank"} and [workshops](http://writing.ucdavis.edu/wac/workshops){:target="_blank"}, as well as specialized programs such as the [Graduate Certificate in Writing Theory and Practice](http://writing.ucdavis.edu/wac/certificate){:target="_blank"} and the [Writing Partner Program](http://writing.ucdavis.edu/wac/resources/writing-partner-program){:target="_blank"}. Lauren developed the curriculum for the Graduate Certificate in Writing Theory and Practice, along with WAC peers [Tori White and Julia Ribeiro](http://writing.ucdavis.edu/wac/gfw-bios){:target="_blank"}. She also conducted numerous research projects which were presented at the following conferences: 

> Mikovits, M., Sperber, L., **Fink, L.** & Prebel, J. (2019, March). Writing Fellows as Agents of Transfer: Training in Threshold Concepts to Support Campus-Wide Sites of Writing. *Symposium presented at the College Composition and Communication Convention, Pittsburgh, PA.*  

> **Fink, L.**, Ribeiro, J., & White, V. (2018, March). Transforming graduate writing experiences: A new Writing Across the Curriculum (WAC) certificate program. *Symposium presented at the College Composition and Communication Convention, Kansas City, MO.*  

> Bright, A., Singleton, J., **Fink, L.**, & Rodger, K. (2017, March). Cultivating a Rhetorical Consciousness: Supporting Graduate Student Writers Across the Curriculum. *Symposium presented at the College Composition and Communication Convention, Portland, OR.*  

> **Fink, L.** & Rodger, K. (2016, June). Mapping neuroscience through professional writing. *Talk presented at the International Writing Across the Curriculum Conference, Ann Arbor, MI.*






